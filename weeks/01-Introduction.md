---
layout: week
title: Week 01
permalink: /weeks/01-Introduction/
doodle: /doodle.png
---

# Introduction to Credit Risk Forecasting

## Topics

This week's assignments will guide you through the following topics:
* Broadly defining credit risk modeling. 
* Reviewing/introducing frameworks that position us well to scale operations.
* Begin a deeper dive into feature engineering techniques. 

## Reading

Please read or view the following:
* Journal Article: [An Investigation of Credit Card Default Prediction in Imbalanced Datasets](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9239944s)
* Video: [Ray: A Framework for Scaling and Distributing Python and ML Applications](https://www.youtube.com/watch?v=LmROEotKhJA)
* Video: [Dask DataFrame: An Introduction](https://www.youtube.com/watch?v=AT2XtFehFSQ)
* Skim this Book Chapter: [Feature Engineering and Selection: Chapter 1](http://www.feat.engineering/intro-intro)
* Read the [docs](https://www.freddiemac.com/research/datasets/sf-loanlevel-dataset) on the Freddie Mac Single Family Loan-Level Dataset. Also review the [user guide](https://www.freddiemac.com/fmac-resources/research/pdf/user_guide.pdf) (pay special attention to pages 7-18). You should also create an account with them to access the data. 

## Tasks 

Let's review the [legacy repository](https://github.com/rodalbuyeh/legacy_code) that has been shared with you. 
Things you should consider: 

* How is this project structured? How is it different from a notebook-based workflow? 
* What feature engineering and modeling techniques are used? 
* What would happen if we ran this workflow on the full sample of data? What would we have to change to make that work?
* Are there opportunities to improve the presentation as indicated? 
  

## Weekly Questions

Answer the following questions on Gradescope:

* What are the challenges inherent to credit risk modeling? 
* Why should we modularize and package our code? 
* How might we scale simple feature engineering? 
For example, how would we run categorical encoding over hundreds of millions of records?

